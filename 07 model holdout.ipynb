{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxMV0DNjRppJ"
   },
   "source": [
    "### 1. importing dataset\n",
    "* separating out x and y\n",
    "* adding monotonic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = pd.read_csv('02 data split 0.csv')\n",
    "s1 = pd.read_csv('02 data split 1.csv')\n",
    "s2 = pd.read_csv('02 data split 2.csv')\n",
    "df = pd.concat([s0,s1,s2])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['IsBadBuy']\n",
    "x = df.drop(['IsBadBuy','RefId'], axis=1)\n",
    "c = []\n",
    "for i in x.columns:\n",
    "    c.append(1)\n",
    "c = tuple(c)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DT\n",
    "* identifying optimal hyper-parameters\n",
    "* performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7696536796536798\n",
      "{'max_depth': 10, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [2,5,10,20],\n",
    "              \"min_samples_leaf\": [2,5,10,20]}\n",
    "model = DecisionTreeClassifier(monotonic_cst=c, random_state=0)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring='roc_auc', cv=3, n_jobs=6)\n",
    "grid_search = grid_search.fit(x,y)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 10)\n",
      "auc roc  : 0.831\n",
      "f1 score : 0.639\n"
     ]
    }
   ],
   "source": [
    "max_depth1 = grid_search.best_params_['max_depth']\n",
    "min_samples_leaf1 = grid_search.best_params_['min_samples_leaf']\n",
    "model = DecisionTreeClassifier(max_depth=max_depth1, min_samples_leaf=min_samples_leaf1, monotonic_cst=c, random_state=0)\n",
    "\n",
    "model.fit(x,y)\n",
    "print(x.shape)\n",
    "pred2 = []\n",
    "pred1 = model.predict_proba(x)[:,1]\n",
    "a1 = roc_auc_score(y,pred1)\n",
    "print('auc roc  :',np.round(a1,3))\n",
    "\n",
    "for j in pred1:\n",
    "    if j > 0.30: pred2.append(1)\n",
    "    else: pred2.append(0)\n",
    "c1 = confusion_matrix(y,pred2)\n",
    "p = c1[1][1] / (c1[0][1]+c1[1][1])\n",
    "r = c1[1][1] / (c1[1][0]+c1[1][1])\n",
    "f1 = (2*p*r) / (p+r)\n",
    "print('f1 score :',np.round(f1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. holdout dataset\n",
    "* providing predictions\n",
    "* adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('06 data holdout.csv')\n",
    "pred2 = []\n",
    "pred1 = model.predict_proba(df)[:,1]\n",
    "for j in pred1:\n",
    "    if j > 0.30: pred2.append(1)\n",
    "    else: pred2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RefId = []\n",
    "for i in range(1000-df.shape[0], 1000):\n",
    "    RefId.append(i)\n",
    "df['RefId'] = RefId\n",
    "df['IsBadBuy'] = pred2\n",
    "df['VehBCost'] = 6500\n",
    "df['Make'] = np.where(df['Make']==1, 'FORD', 'DODGE')\n",
    "df['WheelType'] = np.where(df['WheelType']==1, np.nan, 'Alloy')\n",
    "df['VNST'] = np.where(df['VNST']==1, 'VA', 'FL')\n",
    "\n",
    "df['MMRAcquisitionRetailAveragePrice'] = np.round(df['VehBCost'] / df['MMRAcquisitionRetailAveragePrice'],0)\n",
    "df['MMRAcquisitonRetailCleanPrice'] = np.round(df['VehBCost'] / df['MMRAcquisitonRetailCleanPrice'],0)\n",
    "df['MMRCurrentRetailAveragePrice'] = np.round(df['VehBCost'] / df['MMRCurrentRetailAveragePrice'],0)\n",
    "df['MMRCurrentRetailCleanPrice'] = np.round(df['VehBCost'] / df['MMRCurrentRetailCleanPrice'],0)\n",
    "df['WarrantyCost'] = np.round(df['VehBCost'] * df['WarrantyCost'],0)\n",
    "df['VehicleAge'] = np.round(df['VehicleAge_decades']*10,0)\n",
    "df['VehOdo'] = np.round(df['VehOdo_lakhs']*100000,0)\n",
    "\n",
    "df = df[['RefId', 'IsBadBuy', 'VehBCost', 'Make', 'WheelType', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "         'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', 'VNST', 'WarrantyCost', 'VehicleAge', 'VehOdo']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. exporting dataset\n",
    "* there are 8 numerical variables\n",
    "* there are 3 categorical variables\n",
    "* there are 2 other variables - RefId and IsBadBuy\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('07 model holdout.csv', index=False)\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
